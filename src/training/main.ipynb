{"cells":[{"cell_type":"markdown","metadata":{"id":"JyMQA9yPsofV"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7jVffUnsrip"},"outputs":[],"source":["!pip3 install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGw9C_koyAbV"},"outputs":[],"source":["!pip3 install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtNA6LR83gm0"},"outputs":[],"source":["!pip3 install hydra-core"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywPNiOhKYRfK"},"outputs":[],"source":["!pip3 install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQGQSWfAY6pz"},"outputs":[],"source":["!pip3 install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16537,"status":"ok","timestamp":1671440503874,"user":{"displayName":"박성환","userId":"16608640204304641951"},"user_tz":-540},"id":"Ss8mh3XdzUyI","outputId":"2cfb354f-2d28-4dca-b6dd-f31ab7cb857d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1071,"status":"ok","timestamp":1671375976320,"user":{"displayName":"박성환","userId":"16608640204304641951"},"user_tz":-540},"id":"Xqvd6gpraRFV","outputId":"8a5757f6-0097-4c5f-f404-4a0493104b89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 18 15:06:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1671375976321,"user":{"displayName":"박성환","userId":"16608640204304641951"},"user_tz":-540},"id":"S-ETFYQfaRUK","outputId":"b6d3c445-429b-4041-8876-e7e16c5f59bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"wIw3DXFesrUy"},"source":["# Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2r1uXozsng8"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Hackathon/src/training')\n","\n","!python3 train.py"]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"2jCHSWW0Gb9i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkLDGbLxAzLk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671441169995,"user_tz":-540,"elapsed":22893,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"55dfbe5d-39cc-40b6-f67e-35dd80fce75c"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-19 09:12:27.526702: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","predict_test.py:10: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","당신의 성격:\n","    나는 여자이다.\n","    나는 30대이다.\n","    나는 간호학과를 전공했다\n","    나는 새벽에 산책한다\n","    나는 김치찌개를 좋아한다\n","\n","    speaker1 이전 대화 요약: \n","    speaker2 이전 대화 요약: \n","\n","    대화 요약:\n","    speaker1: 나는 30대 여성이다\n","    speaker2: 나는 40대 여성이다\n","    speaker1: 나는 간호학과를 전공했다. 나는 병원에서 일한다.\n","\n","    다음 내용에 답하세요: 그러시군요. 저는 평택에 거주하고 있는데 이곳의 작은 회사에서 회계일을 하고 있어요.\n","\n","    답변: 세하 요: 세요. : 요 세 요.                                                                                                                                                                                                                                                                                                                                                \n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/Hackathon/src/training')\n","\n","!python3 predict_test.py"]},{"cell_type":"code","source":[],"metadata":{"id":"93BVLqMOGhaZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1k5qvqSzGjHbIQ6cuNMR6Xk8VVyIA7DO8","authorship_tag":"ABX9TyMBbGXxeEuJuzKcQOwNKg1C"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}